{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ END-TO-END MACHINE LEARNING"
      ],
      "metadata": {
        "id": "ZrtMGV2LAQ89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think of Machine Learning (ML) like cooking:\n",
        "\n",
        "Dataset = raw ingredients\n",
        "\n",
        "Preprocessing = cleaning and cutting vegetables\n",
        "\n",
        "Model = recipe\n",
        "\n",
        "Training = cooking\n",
        "\n",
        "Testing = tasting the food\n",
        "\n",
        "Hyperparameters = choices in the recipe (salt, flame level)\n",
        "\n",
        "Parameters = what the model learns from data"
      ],
      "metadata": {
        "id": "AsP4UqsRAUQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ CODE: ML END-TO-END"
      ],
      "metadata": {
        "id": "mPaWohT-AWZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ STEP 1: IMPORT THE REQUIRED LIBRARIES"
      ],
      "metadata": {
        "id": "IuOr0aIyAliC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sklearn provides ready-made datasets and ML models\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# ML models to test\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "V2UizlqxASwV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ STEP 2: CREATE A LIST OF DATASETS"
      ],
      "metadata": {
        "id": "iRCbOnXiAtCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a Python dictionary called \"datasets\".\n",
        "# A dictionary stores data in KEY : VALUE pairs.\n",
        "# Example:\n",
        "#     \"Name\" : \"Arokia\"\n",
        "#\n",
        "# Here, the KEY is the dataset name (a string),\n",
        "# and the VALUE is the actual dataset loaded from sklearn.\n",
        "\n",
        "datasets = {\n",
        "    \"Iris Dataset\"       : load_iris(),          # Flower dataset (predict flower type)\n",
        "    \"Breast Cancer\"      : load_breast_cancer(), # Medical dataset (predict cancer type)\n",
        "    \"Digits Recognition\" : load_digits()         # Image dataset (predict handwritten digit)\n",
        "}\n",
        "\n",
        "# All sklearn datasets follow the SAME structure:\n",
        "#   dataset.data   ‚Üí features (X)\n",
        "#   dataset.target ‚Üí labels   (y)\n",
        "#\n",
        "# So we can loop through this dictionary and treat\n",
        "# every dataset the same way in our ML pipeline.\n"
      ],
      "metadata": {
        "id": "OERcrbrxAYTJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ STEP 3: DEFINE MODELS TO TEST"
      ],
      "metadata": {
        "id": "X-ftGTmoAz5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create another dictionary called \"models\".\n",
        "# KEY   = model name (string)\n",
        "# VALUE = the actual ML model wrapped inside a Pipeline.\n",
        "# ‚úÖ What is a Pipeline?\n",
        "# A Pipeline is like a \"processing machine\" where data enters,\n",
        "# gets cleaned/preprocessed, and then goes to the ML model.\n",
        "#\n",
        "# Why use a Pipeline here?\n",
        "# 1) It scales (normalizes) the data automatically.\n",
        "# 2) It sends the scaled data into the model.\n",
        "# 3) It keeps your code clean and reduces mistakes.\n",
        "# 4) You train everything using ONE line: model.fit()\n",
        "\n",
        "models = {\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # 1Ô∏è‚É£ LOGISTIC REGRESSION PIPELINE\n",
        "    # -------------------------------------------------------------\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),      # Step 1: Standardize features\n",
        "                                           # (Mean = 0, Std = 1)\n",
        "                                           # Helps many models perform better\n",
        "\n",
        "        ('clf', LogisticRegression())      # Step 2: The actual ML model\n",
        "                                           # clf = \"classifier\"\n",
        "    ]),\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # 2Ô∏è‚É£ DECISION TREE PIPELINE\n",
        "    # -------------------------------------------------------------\n",
        "    \"Decision Tree\": Pipeline([\n",
        "        ('scaler', StandardScaler()),      # Scaling still included for consistency,\n",
        "                                           # even though trees do NOT need scaling\n",
        "\n",
        "        ('clf', DecisionTreeClassifier())  # Step 2: Decision Tree model\n",
        "                                           # Learns rules like:\n",
        "                                           # \"If THIS > 5 ‚Üí class A\"\n",
        "    ]),\n",
        "\n",
        "    # -------------------------------------------------------------\n",
        "    # 3Ô∏è‚É£ RANDOM FOREST PIPELINE\n",
        "    # -------------------------------------------------------------\n",
        "    \"Random Forest\": Pipeline([\n",
        "        ('scaler', StandardScaler()),      # Again, scaling is safe and consistent\n",
        "\n",
        "        ('clf', RandomForestClassifier())  # Step 2: Random Forest model\n",
        "                                           # A group of many decision trees\n",
        "                                           # (majority vote)\n",
        "    ])\n",
        "}\n",
        "\n",
        "# Summary:\n",
        "# - All models follow the same structure.\n",
        "# - All models use the SAME preprocessing (scaling).\n",
        "# - This makes it fair to compare them.\n",
        "# - Later, we can simply loop through the \"models\" dictionary\n",
        "#   to train & test every model easily.\n"
      ],
      "metadata": {
        "id": "x5RacLwOAaXz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ STEP 4: LOOP THROUGH EACH DATASET & TEST EVERY MODEL"
      ],
      "metadata": {
        "id": "p9cI3WJDBLiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will loop through:\n",
        "#   1) Each dataset (Iris, Breast Cancer, Digits)\n",
        "#   2) Each model (Logistic Regression, Tree, Forest)\n",
        "#\n",
        "# For every dataset:\n",
        "#   - Split it into train & test\n",
        "#   - Train all models\n",
        "#   - Test all models\n",
        "#   - Print accuracy\n",
        "#   - Pick the best model\n",
        "# -------------------------------------------------\n",
        "\n",
        "for dataset_name, dataset in datasets.items():\n",
        "    # datasets.items() returns:\n",
        "    # (\"Iris Dataset\", <iris_object>)\n",
        "    # (\"Breast Cancer\", <cancer_object>)\n",
        "    # ...\n",
        "    # dataset_name = KEY (string)\n",
        "    # dataset = VALUE (actual sklearn dataset)\n",
        "\n",
        "    print(\"\\n======================================\")\n",
        "    print(f\"üìå DATASET:\", dataset_name)   # Shows which dataset we are testing\n",
        "    print(\"======================================\")\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # EXTRACT FEATURES (X) AND LABELS (y)\n",
        "    # -------------------------------------------------\n",
        "    # X = input data (what we use to predict)\n",
        "    # y = output labels (the correct answers)\n",
        "    X = dataset.data      # All feature columns\n",
        "    y = dataset.target    # The category/class we want to predict\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # SPLIT INTO TRAINING AND TESTING SETS\n",
        "    # -------------------------------------------------\n",
        "    # 80% ‚Üí used to TRAIN the model\n",
        "    # 20% ‚Üí used to TEST the model (unseen data)\n",
        "    # random_state=42 ensures results never change\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # INITIALIZE TRACKING VARIABLES\n",
        "    # -------------------------------------------------\n",
        "    best_model_name = None    # We will store the name of the best model\n",
        "    best_accuracy = 0         # Store its highest accuracy score\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # LOOP THROUGH EACH MODEL\n",
        "    # -------------------------------------------------\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # -------------------------------\n",
        "        # TRAIN THE MODEL\n",
        "        # -------------------------------\n",
        "        # This teaches the model using training data.\n",
        "        # Pipeline automatically:\n",
        "        #   1) Scales the data\n",
        "        #   2) Trains the classifier\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # -------------------------------\n",
        "        # TEST THE MODEL\n",
        "        # -------------------------------\n",
        "        # .score() returns accuracy:\n",
        "        # How many predictions were correct?\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "\n",
        "        # Print model name + accuracy\n",
        "        print(f\"{model_name}: {accuracy:.3f}\")\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # CHECK IF THIS MODEL IS THE BEST ONE (so far)\n",
        "        # -------------------------------------------------\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy       # Update best accuracy\n",
        "            best_model_name = model_name   # Update best model\n",
        "\n",
        "    # -------------------------------------------------\n",
        "    # PRINT BEST MODEL FOR THIS DATASET\n",
        "    # -------------------------------------------------\n",
        "    print(f\"‚úÖ BEST MODEL: {best_model_name} with accuracy {best_accuracy:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMKEtEzaAcSG",
        "outputId": "e2eacea8-27cf-462b-ae5a-c7de157b18fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================\n",
            "üìå DATASET: Iris Dataset\n",
            "======================================\n",
            "Logistic Regression: 1.000\n",
            "Decision Tree: 1.000\n",
            "Random Forest: 1.000\n",
            "‚úÖ BEST MODEL: Logistic Regression with accuracy 1.000\n",
            "\n",
            "======================================\n",
            "üìå DATASET: Breast Cancer\n",
            "======================================\n",
            "Logistic Regression: 0.974\n",
            "Decision Tree: 0.947\n",
            "Random Forest: 0.965\n",
            "‚úÖ BEST MODEL: Logistic Regression with accuracy 0.974\n",
            "\n",
            "======================================\n",
            "üìå DATASET: Digits Recognition\n",
            "======================================\n",
            "Logistic Regression: 0.972\n",
            "Decision Tree: 0.847\n",
            "Random Forest: 0.975\n",
            "‚úÖ BEST MODEL: Random Forest with accuracy 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUMMARY\n",
        "\n",
        "‚úÖ You loop through datasets like this:"
      ],
      "metadata": {
        "id": "iQCO5luXBUyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iris ‚Üí test all models ‚Üí choose best\n",
        "\n",
        "Breast Cancer ‚Üí test all models ‚Üí choose best\n",
        "\n",
        "Digits ‚Üí test all models ‚Üí choose best"
      ],
      "metadata": {
        "id": "Sl4f9GJJBXBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Pipelines automatically clean and scale data.\n",
        "\n",
        "‚úÖ .fit() = training\n",
        "\n",
        "‚úÖ .score() = test accuracy\n",
        "\n",
        "‚úÖ You compare accuracy and choose the highest."
      ],
      "metadata": {
        "id": "iaL51GaDBanl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Why multiple datasets?\n",
        "\n",
        "Because each dataset has different patterns.\n",
        "We want to check:\n",
        "\n",
        "‚úÖ Which model works on flowers? (IRIS)\n",
        "\n",
        "‚úÖ Which model works on images? (Digits)\n",
        "\n",
        "‚úÖ Which model works on medical data? (Cancer)"
      ],
      "metadata": {
        "id": "pPXzI5p4BfXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Why Pipelines?\n",
        "\n",
        "Pipeline = A box that automatically does:\n",
        "\n",
        "Scale data\n",
        "\n",
        "Train model\n",
        "\n",
        "Instead of writing:"
      ],
      "metadata": {
        "id": "Mf3DNrdFBkJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scaler.fit()\n",
        "\n",
        "scaler.transform()\n",
        "\n",
        "model.fit()"
      ],
      "metadata": {
        "id": "AphoSJ1NBmhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You write only:\n",
        "pipeline.fit()"
      ],
      "metadata": {
        "id": "KCGuk5gfBwxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Why train-test split?\n",
        "\n",
        "We want to check if the model works on new data it has never seen."
      ],
      "metadata": {
        "id": "oX5C0vdHB1sv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Why use .fit()?\n",
        "\n",
        "Training = model learning patterns.\n",
        "\n",
        "‚úÖ Why use .score()?\n",
        "\n",
        "Testing = model accuracy.\n",
        "\n",
        "‚úÖ Why use .predict()?\n",
        "\n",
        "Prediction = model giving answer.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "_ChSSBZjB23a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.predict([[5.1, 3.5, 1.4, 0.2]])"
      ],
      "metadata": {
        "id": "tCGZVOhvB-AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ FINAL OUTCOME\n",
        "\n",
        "You built a system that:\n",
        "\n",
        "‚úÖ Loads multiple datasets\n",
        "\n",
        "‚úÖ Trains 3 different ML models\n",
        "\n",
        "‚úÖ Tests each model\n",
        "\n",
        "‚úÖ Automatically finds the best model\n",
        "\n",
        "‚úÖ Works for absolute beginners\n",
        "\n",
        "‚úÖ Fully end-to-end"
      ],
      "metadata": {
        "id": "lT2bSDlCCEo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMBALANCED DATA\n",
        "\n",
        "‚úÖ 1. What is imbalanced data?\n",
        "\n",
        "Imbalanced data means:\n",
        "\n",
        "One class has many samples\n",
        "\n",
        "Another class has very few\n",
        "\n",
        "Example:\n",
        "\n",
        "990 normal emails\n",
        "\n",
        "10 spam emails\n",
        "\n",
        "üëâ Accuracy becomes meaningless.\n",
        "\n",
        "A model can say ‚ÄúEverything is normal‚Äù and still get 990/1000 correct ‚Üí 99% accuracy. But it failed completely at detecting spam.\n",
        "\n",
        "So accuracy is not useful for imbalanced datasets.\n",
        "\n",
        "BEST METRICS FOR IMBALANCED DATA\n",
        "\n",
        "‚úÖ ‚úÖ (1) Precision\n",
        "\n",
        "Of all predicted positives, how many are correct?\n",
        "\n",
        "Useful when false positives are dangerous. Example: Spam filter (don't mark real emails as spam).\n",
        "\n",
        "‚úÖ ‚úÖ (2) Recall\n",
        "\n",
        "Of all actual positives, how many did the model catch?\n",
        "\n",
        "Useful when false negatives are dangerous. Example: Cancer detection (don‚Äôt miss sick patients).\n",
        "\n",
        "‚úÖ ‚úÖ (3) F1-Score\n",
        "\n",
        "Balance between Precision and Recall\n",
        "\n",
        "Use when: Data is imbalanced  You want a single, fair metric\n",
        "\n",
        "‚úÖ ‚úÖ (4) Confusion Matrix\n",
        "\n",
        "A table showing correct/incorrect predictions. Very useful to see mistakes clearly."
      ],
      "metadata": {
        "id": "pYH7Mf32CPyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ SUMMARY TABLE\n",
        "| Situation                               | Best Metric           |\n",
        "| --------------------------------------- | --------------------- |\n",
        "| Data imbalanced                         | **F1-score** |\n",
        "| Missing positives is dangerous (cancer) | **Recall**            |\n",
        "| False alarms are dangerous (spam)       | **Precision**         |\n",
        "| Want a visual mistake summary           | **Confusion Matrix**  |\n",
        "| Balanced data                           | **Accuracy** is fine  |\n"
      ],
      "metadata": {
        "id": "HI74HGONCaiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ THE SIMPLEST RULE\n",
        "\n",
        "üëâ For imbalanced datasets, DO NOT USE Accuracy\n",
        "\n",
        "üëâ Use F1-score"
      ],
      "metadata": {
        "id": "maJVLv7jCc4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Models on Different Imbalanced Datasets"
      ],
      "metadata": {
        "id": "Jrwr94XnChc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use 3 datasets:\n",
        "\n",
        "1Ô∏è‚É£ Breast Cancer Dataset ‚Äì slightly imbalanced\n",
        "\n",
        "2Ô∏è‚É£ Make_Classification (Custom Synthetic Data) ‚Äì heavily imbalanced\n",
        "\n",
        "3Ô∏è‚É£ Credit Card Fraud Dataset (simulated) ‚Äì extremely imbalanced"
      ],
      "metadata": {
        "id": "waO1vSDOCj2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: IMPORT LIBRARIES\n",
        "from sklearn.datasets import load_breast_cancer, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# ML models to test\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Metrics for imbalanced data\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "WtYimLBoBOnS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: CREATE MULTIPLE IMBALANCED DATASETS\n",
        "# We make a dictionary called \"datasets\" that will store\n",
        "# all our imbalanced datasets.\n",
        "#\n",
        "# Why?\n",
        "# Because later we want to LOOP through them and test\n",
        "# every ML model on every dataset easily.\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Breast Cancer dataset (slightly imbalanced)\n",
        "# ---------------------------------------------------------\n",
        "# This dataset comes built-in from sklearn.\n",
        "# It has two classes:\n",
        "#   - 0 : malignant (cancer)\n",
        "#   - 1 : benign (non-cancer)\n",
        "#\n",
        "# The dataset is not perfectly balanced.\n",
        "# One class has more samples than the other.\n",
        "datasets[\"Breast Cancer\"] = load_breast_cancer()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Synthetic dataset (artificially created)\n",
        "# ---------------------------------------------------------\n",
        "# We create our own dataset using make_classification().\n",
        "#\n",
        "# n_samples   = total rows of data\n",
        "# n_features  = number of columns/features\n",
        "# weights     = class distribution\n",
        "#               0.9 means 90%\n",
        "#               0.1 means 10%\n",
        "#\n",
        "# So we are creating:\n",
        "#   - Class 0 ‚Üí 90% of data\n",
        "#   - Class 1 ‚Üí 10% of data\n",
        "#\n",
        "# This simulates real-world imbalance like:\n",
        "#   - disease (rare)\n",
        "#   - machine failure (rare)\n",
        "#   - fraud detection (rare)\n",
        "X_syn, y_syn = make_classification(\n",
        "    n_samples=3000,\n",
        "    n_features=10,\n",
        "    weights=[0.9, 0.1],        # 90% vs 10% imbalance\n",
        "    random_state=42            # ensures the same output every time\n",
        ")\n",
        "\n",
        "# We store this dataset in our dictionary.\n",
        "# We use a small dictionary for each dataset:\n",
        "#     {\"data\": X, \"target\": y}\n",
        "datasets[\"Synthetic 90:10\"] = {\"data\": X_syn, \"target\": y_syn}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Simulated Credit Card Fraud dataset\n",
        "# ---------------------------------------------------------\n",
        "# We create another synthetic dataset, but now with\n",
        "# EXTREME imbalance:\n",
        "#\n",
        "#   - Class 0 ‚Üí 99.2%\n",
        "#   - Class 1 ‚Üí 0.8% (almost no fraud)\n",
        "#\n",
        "# This represents real financial fraud data.\n",
        "# Fraud cases are VERY rare.\n",
        "X_fraud, y_fraud = make_classification(\n",
        "    n_samples=5000,\n",
        "    n_features=15,\n",
        "    weights=[0.992, 0.008],   # EXTREME imbalance (99:1)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Store this dataset in our main dictionary\n",
        "datasets[\"Credit Fraud 99:1\"] = {\"data\": X_fraud, \"target\": y_fraud}\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# ‚úÖ Summary for Absolute Beginners:\n",
        "# ---------------------------------------------------------\n",
        "# ‚úÖ We now have 3 datasets:\n",
        "#     1) Breast Cancer (slightly imbalanced)\n",
        "#     2) Synthetic 90:10 (moderately imbalanced)\n",
        "#     3) Credit Fraud 99:1 (extremely imbalanced)\n",
        "#\n",
        "# ‚úÖ All datasets are stored in ONE dictionary (datasets)\n",
        "#    so we can loop through them later.\n",
        "#\n",
        "# ‚úÖ Using imbalanced datasets helps us learn which models\n",
        "#    and metrics work best when one class is very rare.\n"
      ],
      "metadata": {
        "id": "B9YR_YKzCqi-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: DEFINE MODELS TO TEST\n",
        "\n",
        "# We create a dictionary called 'models'\n",
        "# Each key = name of the model (text)\n",
        "# Each value = the actual model inside a Pipeline\n",
        "models = {\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 1Ô∏è‚É£ Logistic Regression\n",
        "    # -----------------------------------------------------\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "\n",
        "        # Step A: Scale the data\n",
        "        # StandardScaler makes all features (columns)\n",
        "        # have similar ranges so the model learns better.\n",
        "        ('scaler', StandardScaler()),\n",
        "\n",
        "        # Step B: Our actual ML model\n",
        "        # Logistic Regression is a simple classification model.\n",
        "        ('clf', LogisticRegression())\n",
        "    ]),\n",
        "\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 2Ô∏è‚É£ Decision Tree Classifier\n",
        "    # -----------------------------------------------------\n",
        "    \"Decision Tree\": Pipeline([\n",
        "\n",
        "        # Step A: Scale features ‚Äî not required for trees,\n",
        "        # but keeping everything consistent for beginners.\n",
        "        ('scaler', StandardScaler()),\n",
        "\n",
        "        # Step B: Decision Tree model\n",
        "        # It learns by splitting data like a flowchart.\n",
        "        ('clf', DecisionTreeClassifier())\n",
        "    ]),\n",
        "\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # 3Ô∏è‚É£ Random Forest Classifier\n",
        "    # -----------------------------------------------------\n",
        "    \"Random Forest\": Pipeline([\n",
        "\n",
        "        # Step A: Scaling ‚Äî again for consistency\n",
        "        ('scaler', StandardScaler()),\n",
        "\n",
        "        # Step B: Random Forest model\n",
        "        # A forest = many decision trees working together.\n",
        "        # Usually performs better than a single tree.\n",
        "        ('clf', RandomForestClassifier())\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "A8o3Y57uCw82"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test ALL Models on ALL Imbalanced Datasets"
      ],
      "metadata": {
        "id": "lOwnVsBUC4WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: LOOP THROUGH EACH DATASET\n",
        "\n",
        "# Loop through every dataset we created in Step 2\n",
        "# dataset_name  = text (ex: \"Breast Cancer\")\n",
        "# dataset       = actual data (X, y)\n",
        "for dataset_name, dataset in datasets.items():\n",
        "\n",
        "    # Print the dataset name so we know which one is running\n",
        "    print(\"\\n======================================\")\n",
        "    print(\"üìå DATASET:\", dataset_name)\n",
        "    print(\"======================================\")\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Some datasets (like Breast Cancer) come as sklearn objects.\n",
        "    # Others (our synthetic ones) are Python dictionaries.\n",
        "    # So we check the type and extract X, y correctly.\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    # If dataset is a normal dictionary\n",
        "    if isinstance(dataset, dict):\n",
        "        X = dataset[\"data\"]     # features (inputs)\n",
        "        y = dataset[\"target\"]   # labels (outputs)\n",
        "    else:\n",
        "        # If dataset is a sklearn dataset object\n",
        "        X = dataset.data\n",
        "        y = dataset.target\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Split data into Train (80%) and Test (20%)\n",
        "    # Train ‚Üí used to teach the model\n",
        "    # Test ‚Üí used to check how well model performs\n",
        "    # -----------------------------------------------------\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Variables to store the best model for this dataset\n",
        "    # We use F1-Score because data is imbalanced.\n",
        "    # -----------------------------------------------------\n",
        "    best_model_name = None\n",
        "    best_f1 = 0\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # Test EACH model (logistic, tree, random forest)\n",
        "    # -----------------------------------------------------\n",
        "    for model_name, model in models.items():\n",
        "\n",
        "        # ‚úÖ Train the model using training data\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # ‚úÖ Make predictions on the test data\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # ‚úÖ Needed for ROC-AUC (probability of class 1)\n",
        "        y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # ‚úÖ Calculate evaluation metrics for IMBALANCED DATA\n",
        "        # Precision ‚Üí Of all predicted positive, how many correct?\n",
        "        # Recall    ‚Üí Of all actual positive, how many found?\n",
        "        # F1 Score  ‚Üí Balance between Precision & Recall\n",
        "        # -------------------------------------------------\n",
        "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"\\nüîπ {model_name}\")\n",
        "        print(\"Precision:\", round(precision, 3))\n",
        "        print(\"Recall:   \", round(recall, 3))\n",
        "        print(\"F1 Score: \", round(f1, 3))\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Keep the model with the highest F1-Score\n",
        "        # -------------------------------------------------\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_model_name = model_name\n",
        "\n",
        "    # ‚úÖ After testing all models, print the best one\n",
        "    print(f\"\\n‚úÖ BEST MODEL (based on F1): {best_model_name} ‚Äî F1 = {best_f1:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYJuoCNeC1u0",
        "outputId": "c747117e-d46d-4c77-a4ea-d85b6ea13709"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================\n",
            "üìå DATASET: Breast Cancer\n",
            "======================================\n",
            "\n",
            "üîπ Logistic Regression\n",
            "Precision: 0.972\n",
            "Recall:    0.986\n",
            "F1 Score:  0.979\n",
            "\n",
            "üîπ Decision Tree\n",
            "Precision: 0.944\n",
            "Recall:    0.958\n",
            "F1 Score:  0.951\n",
            "\n",
            "üîπ Random Forest\n",
            "Precision: 0.959\n",
            "Recall:    0.986\n",
            "F1 Score:  0.972\n",
            "\n",
            "‚úÖ BEST MODEL (based on F1): Logistic Regression ‚Äî F1 = 0.979\n",
            "\n",
            "======================================\n",
            "üìå DATASET: Synthetic 90:10\n",
            "======================================\n",
            "\n",
            "üîπ Logistic Regression\n",
            "Precision: 0.871\n",
            "Recall:    0.831\n",
            "F1 Score:  0.85\n",
            "\n",
            "üîπ Decision Tree\n",
            "Precision: 0.864\n",
            "Recall:    0.877\n",
            "F1 Score:  0.87\n",
            "\n",
            "üîπ Random Forest\n",
            "Precision: 0.965\n",
            "Recall:    0.846\n",
            "F1 Score:  0.902\n",
            "\n",
            "‚úÖ BEST MODEL (based on F1): Random Forest ‚Äî F1 = 0.902\n",
            "\n",
            "======================================\n",
            "üìå DATASET: Credit Fraud 99:1\n",
            "======================================\n",
            "\n",
            "üîπ Logistic Regression\n",
            "Precision: 0.0\n",
            "Recall:    0.0\n",
            "F1 Score:  0.0\n",
            "\n",
            "üîπ Decision Tree\n",
            "Precision: 0.143\n",
            "Recall:    0.231\n",
            "F1 Score:  0.176\n",
            "\n",
            "üîπ Random Forest\n",
            "Precision: 0.75\n",
            "Recall:    0.231\n",
            "F1 Score:  0.353\n",
            "\n",
            "‚úÖ BEST MODEL (based on F1): Random Forest ‚Äî F1 = 0.353\n"
          ]
        }
      ]
    }
  ]
}