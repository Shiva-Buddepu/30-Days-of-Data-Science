{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ§  Scikit-learn Pipeline"
      ],
      "metadata": {
        "id": "pr2Ge1YI8VGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ’¡ What is a Pipeline?\n",
        "\n",
        "A Pipeline in scikit-learn is like an assembly line in a factory ðŸ­.\n",
        "\n",
        "Example ) Each Titanic passenger (your data row) moves through a series of stations (steps):\n",
        "\n",
        "      1ï¸âƒ£ Data cleaning / transformation\n",
        "      2ï¸âƒ£ Model training or prediction\n",
        "\n",
        "Everything happens in order, automatically."
      ],
      "metadata": {
        "id": "72BGI9D-8YqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŽ¯ Real-World Analogy\n",
        "\n",
        "Imagine the Titanic Rescue Prediction System:\n",
        "\n",
        "| Step                       | Analogy                | Machine Learning Step |\n",
        "| -------------------------- | ---------------------- | --------------------- |\n",
        "| 1ï¸âƒ£ Passenger enters       | Input data             | Dataset               |\n",
        "| 2ï¸âƒ£ Officer checks details | Scale / transform data | Preprocessing         |\n",
        "| 3ï¸âƒ£ Captain decides        | Predict survival       | Classifier            |\n",
        "\n",
        "\n",
        "The Pipeline makes sure every passenger goes through the same process â€” no skipping!"
      ],
      "metadata": {
        "id": "oKc7oCWe8c-R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§© Why Use a Pipeline?\n",
        "| Reason           | Simple Explanation                                                     |\n",
        "| ---------------- | ---------------------------------------------------------------------- |\n",
        "| âœ… Clean code     | Combines all steps in one object                                       |\n",
        "| âš™ï¸ Automation    | Automatically applies preprocessing before training & testing          |\n",
        "| ðŸš€ Reusability   | Reuse same pipeline for new data                                       |\n",
        "| â›” Fewer mistakes | Prevents â€œdata leakageâ€ (using test data accidentally during training) |\n"
      ],
      "metadata": {
        "id": "_HL_Z21s8f1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§° Basic Syntax"
      ],
      "metadata": {
        "id": "wvXjzxh18ijC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create pipeline with two steps:\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),        # Step 1: scale data\n",
        "    ('classifier', LogisticRegression()) # Step 2: train model\n",
        "])"
      ],
      "metadata": {
        "id": "CbJt1qYd8WwS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think of a Pipeline as a conveyor belt or an assembly line ðŸ­\n",
        "  - Every piece of data (like a passenger record in the Titanic dataset) goes through each step in order.\n",
        "\n",
        "        The first step cleans or transforms the data.\n",
        "\n",
        "        The second step trains or predicts using a machine learning model.\n",
        "\n",
        "So you can â€œchainâ€ multiple steps together into one object â€” called a pipeline."
      ],
      "metadata": {
        "id": "eDJOVi7_8nam"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âš™ï¸ What the code means:\n",
        "\n",
        "a) pipe =\n",
        "\n",
        "We are creating a new pipeline object and storing it in a variable named pipe.\n",
        "You can later use this variable to:\n",
        "\n",
        "    Train it â†’ pipe.fit(X_train, y_train)\n",
        "\n",
        "    Test it â†’ pipe.score(X_test, y_test)\n",
        "\n",
        "    Predict â†’ pipe.predict(X_new)"
      ],
      "metadata": {
        "id": "6-ZQ1ab981gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 â€” fit(): Training\n",
        "\n",
        "You are teaching your model.\n",
        "Like a student learning from examples â€” it studies X_train (features) and y_train (answers).\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "ðŸ‘‰ This step builds the modelâ€™s â€œknowledgeâ€.\n",
        "\n",
        "Step 2 â€” score(): Testing\n",
        "\n",
        "Now you check how well your model performs on test data it has never seen before.\n",
        "\n",
        "pipe.score(X_test, y_test)\n",
        "\n",
        "\n",
        "ðŸ‘‰ This step gives you a number between 0 and 1 (like 0.89 = 89% accuracy).\n",
        "\n",
        "Step 3 â€” predict(): Making New Predictions\n",
        "\n",
        "Finally, you can use the trained model to make predictions on brand new data (like a real Titanic passenger record).\n",
        "\n",
        "pipe.predict(X_new)\n",
        "\n",
        "\n",
        "ðŸ‘‰ Output might look like: [0, 1, 1, 0]\n",
        "Here 1 means Survived, 0 means Did not survive."
      ],
      "metadata": {
        "id": "eMbs6Oft8359"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Pipeline([...])\n",
        "\n",
        "The Pipeline() function comes from scikit-learn (a Python library for machine learning).\n",
        "It takes a list of steps as input â€” written inside square brackets [ ... ].\n",
        "\n",
        "Each step is written as a pair of:"
      ],
      "metadata": {
        "id": "GhIV6pXO87JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "('step_name', StepObject)"
      ],
      "metadata": {
        "id": "3qecRgtu9IRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tuple is just a pair or group of values kept together\n",
        "\n",
        "In scikit-learnâ€™s Pipeline,\n",
        "each step must be given as a tuple:\n",
        "\n",
        "('step_name', StepObject)\n",
        "\n",
        "\n",
        "Letâ€™s break that down ðŸ‘‡\n",
        "\n",
        "| Part          | Meaning                                          | Example                                    |\n",
        "| ------------- | ------------------------------------------------ | ------------------------------------------ |\n",
        "| `'step_name'` | A **label (string)** you choose to name the step | `'scaler'`, `'classifier'`                 |\n",
        "| `StepObject`  | The **actual object** that does the work         | `StandardScaler()`, `LogisticRegression()` |\n"
      ],
      "metadata": {
        "id": "9S_vUv1J9LqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1**: 'scaler', StandardScaler()\n",
        "\n",
        "This step tells the pipeline:\n",
        "\n",
        "â€œBefore you train the model, scale all numeric features so that they have similar ranges.â€\n",
        "\n",
        "Why?\n",
        "\n",
        "    Some columns like Age might go from 0â€“80\n",
        "\n",
        "    Others like Fare might go from 0â€“500\n",
        "    This difference can confuse the model.\n",
        "\n",
        "So **StandardScaler()** changes the values so they all have:\n",
        "\n",
        "    Mean (average) â‰ˆ 0\n",
        "\n",
        "    Standard deviation â‰ˆ 1\n",
        "\n",
        "ðŸ‘‰ After scaling, the model learns faster and performs better."
      ],
      "metadata": {
        "id": "ZmgHL0ic9OX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ¤– 4ï¸âƒ£**Step 2**: 'classifier', LogisticRegression()\n",
        "\n",
        "This step tells the pipeline:\n",
        "\n",
        "â€œNow train a machine learning model to predict the output.â€\n",
        "\n",
        "    Here the model is LogisticRegression(), which is commonly used for binary classification (two outcomes â€” e.g., survived or not survived).\n",
        "\n",
        "    The model learns patterns between input features (pclass, age, fare, etc.) and the target (survived)."
      ],
      "metadata": {
        "id": "oV608PYO9STW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§­ 5ï¸âƒ£ How the Pipeline Works (Internally)\n",
        "\n",
        "When you run:"
      ],
      "metadata": {
        "id": "Ew_NtTwf9VyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipe.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "4E-Ipp4G9ZHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‰ The pipeline automatically does:\n",
        "\n",
        "    StandardScaler.fit_transform(X_train) â€” fits and scales the training data\n",
        "\n",
        "    LogisticRegression.fit(scaled_X_train, y_train) â€” trains the model using scaled data\n",
        "\n",
        "When you later run:"
      ],
      "metadata": {
        "id": "MHkjt_ye9cez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipe.predict(X_test)\n"
      ],
      "metadata": {
        "id": "h2oAJOqG9hY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‰ It automatically does:\n",
        "\n",
        "    StandardScaler.transform(X_test) â€” scales new data (using the same scaling learned from training)\n",
        "\n",
        "    LogisticRegression.predict(scaled_X_test) â€” predicts the outcome"
      ],
      "metadata": {
        "id": "ZO1_dFly9jVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“¦ Why Use a Pipeline?\n",
        "\n",
        "Without a pipeline, youâ€™d have to do this manually every time:"
      ],
      "metadata": {
        "id": "a6w7Zahg9ncX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "model.score(X_test_scaled, y_test)"
      ],
      "metadata": {
        "id": "tlj18hQL9q52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With a pipeline ðŸ‘‡"
      ],
      "metadata": {
        "id": "phu0vf6491i7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipe.fit(X_train, y_train) # Train\n",
        "\n",
        "pipe.score(X_test, y_test) # Test"
      ],
      "metadata": {
        "id": "qvSg4jmJ94rL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸ§¾ Summary Table\n",
        "\n",
        "| Part                   | Meaning                                  | Example                      |\n",
        "| ---------------------- | ---------------------------------------- | ---------------------------- |\n",
        "| `Pipeline()`           | Combines multiple steps into one process | `Pipeline([...])`            |\n",
        "| `'scaler'`             | Name for step 1                          | Label for `StandardScaler()` |\n",
        "| `StandardScaler()`     | Scales (normalizes) the numeric data     | Makes all columns comparable |\n",
        "| `'classifier'`         | Name for step 2                          | Label for the model          |\n",
        "| `LogisticRegression()` | The ML model that learns patterns        | Predicts survival (0 or 1)   |\n",
        "| `pipe.fit()`           | Trains both steps automatically          | Scales â†’ trains              |\n",
        "| `pipe.predict()`       | Predicts with both steps                 | Scales â†’ predicts            |\n"
      ],
      "metadata": {
        "id": "8HXX_fMm94uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Much cleaner and less error-prone! âœ…"
      ],
      "metadata": {
        "id": "BjdYJGK59-80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Concept         | What It Means                          | Example                      |\n",
        "| --------------- | -------------------------------------- | ---------------------------- |\n",
        "| **Pipeline**    | Combines multiple steps into one model | `Pipeline([...])`            |\n",
        "| **Transformer** | Changes data (e.g., scale, encode)     | `StandardScaler()`           |\n",
        "| **Estimator**   | Learns from data                       | `LogisticRegression()`       |\n",
        "| **fit()**       | Trains entire pipeline                 | `pipe.fit(X_train, y_train)` |\n",
        "| **score()**     | Tests model accuracy                   | `pipe.score(X_test, y_test)` |\n",
        "| **predict()**   | Makes predictions                      | `pipe.predict(X_new)`        |\n"
      ],
      "metadata": {
        "id": "hf6NNlhN-DwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŽ“ Simple Analogy (Titanic Style ðŸš¢)\n",
        "\n",
        "| Stage        | Analogy                                                  | ML Step            |\n",
        "| ------------ | -------------------------------------------------------- | ------------------ |\n",
        "| ðŸ§¼ Step 1    | Clean passengersâ€™ data (StandardScaler)                  | Normalize inputs   |\n",
        "| ðŸ‘¨â€âœˆï¸ Step 2 | Captain decides who survives (LogisticRegression)        | Predict output     |\n",
        "| ðŸ”„ Pipeline  | Shipâ€™s system ensuring both steps always happen in order | Automated workflow |\n"
      ],
      "metadata": {
        "id": "VPai52x8-HcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… Final Takeaway\n",
        "This single line:"
      ],
      "metadata": {
        "id": "KvsJ7V6H-KOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])"
      ],
      "metadata": {
        "id": "2xsfDmz0-P5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â€¦ creates an automatic machine learning flow where:\n",
        "\n",
        "Data is scaled,\n",
        "\n",
        "Model is trained,\n",
        "\n",
        "You can use one simple object (pipe) for everything â€” training, testing, and predicting."
      ],
      "metadata": {
        "id": "rD_vnyiu-Sov"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§­ How Data Flows in a Pipeline"
      ],
      "metadata": {
        "id": "s1CXxK0T-Uux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train  â”€â”€â”€â–¶  Scaler  â”€â”€â”€â–¶  Classifier (fit)\n",
        "\n",
        "X_test   â”€â”€â”€â–¶  Scaler  â”€â”€â”€â–¶  Classifier (predict)"
      ],
      "metadata": {
        "id": "NfZVwsNG-XLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything runs automatically in the correct order âœ…"
      ],
      "metadata": {
        "id": "dbU-NTZ9-bwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary\n",
        "\n",
        "ðŸ§© A Pipeline = step-by-step machine for your data.\n",
        "\n",
        "âš™ï¸ It ensures same processing during training and testing.\n",
        "\n",
        "ðŸ§¹ It makes your ML code clean, safe, and reusable.\n",
        "\n",
        "ðŸš€ Great for real-world ML projects â€” especially when combining scaling, encoding, or modeling."
      ],
      "metadata": {
        "id": "FQ0TQi-o-fts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Titanic Pipeline: Detailed Inline Comments for Absolute Beginners\n",
        "# -----------------------------\n",
        "\n",
        "# 1) Import libraries we need\n",
        "# pandas: for data tables (DataFrame). seaborn: to load the Titanic dataset easily.\n",
        "# sklearn: for machine learning tools (train/test split, scaler, pipeline and classifiers).\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split          # to split data into train and test sets\n",
        "from sklearn.preprocessing import StandardScaler             # to scale numeric features (important for many ML models)\n",
        "from sklearn.pipeline import Pipeline                         # to create a pipeline (chain of steps)\n",
        "from sklearn.linear_model import LogisticRegression           # a simple classification model\n",
        "from sklearn.tree import DecisionTreeClassifier               # another model for comparison\n",
        "from sklearn.ensemble import RandomForestClassifier           # stronger ensemble model\n",
        "\n",
        "# 2) Load the Titanic dataset\n",
        "# seaborn has a built-in copy of the Titanic dataset which is convenient for learning.\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# 3) Quick look at the data (uncomment to inspect)\n",
        "# print(titanic.head())           # shows the first 5 rows of the dataset\n",
        "# print(titanic.info())           # shows data columns, non-null counts and types\n",
        "# print(titanic.describe())       # shows summary statistics for numeric columns\n",
        "\n",
        "# 4) Select only a few useful columns for beginners\n",
        "# - 'survived' is the target variable (0 = did not survive, 1 = survived).\n",
        "# - 'pclass' = passenger class (1,2,3) numeric already\n",
        "# - 'sex' = categorical; we'll convert to numbers (male/female)\n",
        "# - 'age' = passenger age (numeric)\n",
        "# - 'fare' = ticket fare (numeric)\n",
        "data = titanic[['survived', 'pclass', 'sex', 'age', 'fare']]\n",
        "\n",
        "# 5) Handle missing values\n",
        "# For simplicity (absolute beginner), we drop rows with any missing values.\n",
        "# In real projects you might impute (fill) missing values instead.\n",
        "data = data.dropna()  # drop rows with NaN in any of the chosen columns\n",
        "\n",
        "# 6) Convert categorical text to numbers\n",
        "# ML models need numeric input. Convert 'sex' from 'male'/'female' -> 0/1.\n",
        "# We use a simple mapping: male -> 0, female -> 1\n",
        "data['sex'] = data['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# 7) Define features (X) and target (y)\n",
        "# X is the input data (columns we will use to predict). y is the label (survived).\n",
        "X = data[['pclass', 'sex', 'age', 'fare']]  # features (a DataFrame)\n",
        "y = data['survived']                        # target (a Series)\n",
        "\n",
        "# 8) Split the data into training and testing sets\n",
        "# - X_train, y_train will be used to train the model.\n",
        "# - X_test, y_test will be used to evaluate how the model performs on unseen data.\n",
        "# test_size=0.3 means 30% of data is reserved for testing.\n",
        "# random_state ensures reproducible results (same split each run).\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 9) Create pipelines for different models\n",
        "# A Pipeline chains preprocessing steps and the model itself so you never forget to apply the same preprocessing to train & test.\n",
        "# Each pipeline has 2 steps:\n",
        "#   ('scaler', StandardScaler()) -> scales numeric features to have mean ~0 and std ~1\n",
        "#   ('classifier', <model>)      -> the machine learning model that learns to predict survival\n",
        "#\n",
        "# IMPORTANT: We do NOT scale the target y. Only X (features) are scaled.\n",
        "pipe_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(random_state=42, max_iter=200))\n",
        "])\n",
        "\n",
        "pipe_dt = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "pipe_rf = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
        "])\n",
        "\n",
        "# 10) Put all pipelines in a list so we can loop through them easily\n",
        "pipelines = [pipe_lr, pipe_dt, pipe_rf]\n",
        "model_names = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest'}\n",
        "\n",
        "# 11) Train each pipeline and evaluate on the test set\n",
        "best_accuracy = 0            # variable to store the highest accuracy observed\n",
        "best_model_name = None       # store the name of the best model\n",
        "\n",
        "for i, model in enumerate(pipelines):\n",
        "    # Fit the pipeline on training data.\n",
        "    # Behind the scenes:\n",
        "    #   - StandardScaler.fit_transform(X_train) is applied\n",
        "    #   - the classifier.fit(scaled_X_train, y_train) is applied\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate model on the test data: model.score calls scaler.transform(X_test) then classifier.score\n",
        "    score = model.score(X_test, y_test)\n",
        "\n",
        "    # Print the result for this model\n",
        "    print(f\"{model_names[i]} Test Accuracy: {score:.3f}\")\n",
        "\n",
        "    # Keep track of the best performing model\n",
        "    if score > best_accuracy:\n",
        "        best_accuracy = score\n",
        "        best_model_name = model_names[i]\n",
        "\n",
        "print(\"\\nâœ… Best Model:\", best_model_name, \"with Accuracy:\", round(best_accuracy, 3))\n",
        "\n",
        "# 12) Example: Use the best pipeline to make a single prediction\n",
        "# For clarity we will just demonstrate with the Logistic Regression pipeline (pipe_lr).\n",
        "# In practice, you would pick the 'best' pipeline above and use that object.\n",
        "\n",
        "# Build a sample passenger:\n",
        "# pclass=3 (third class), sex=0 (male), age=25, fare=7.25\n",
        "sample_passenger = [[3, 0, 25, 7.25]]\n",
        "\n",
        "# We must use the pipeline that was fitted earlier. If you're using the best model, pick that pipeline.\n",
        "# Here we demonstrate with pipe_lr (which is fitted above).\n",
        "pred = pipe_lr.predict(sample_passenger)  # pipeline will scale the sample before prediction\n",
        "\n",
        "if pred[0] == 1:\n",
        "    print(\"Sample prediction -> SURVIVED (1)\")\n",
        "else:\n",
        "    print(\"Sample prediction -> DID NOT SURVIVE (0)\")\n",
        "\n",
        "# 13) Optional: Show shape and a sanity check\n",
        "print(\"\\nTraining features shape:\", X_train.shape)\n",
        "print(\"Testing features shape :\", X_test.shape)\n",
        "print(\"Total rows used (after dropping missing):\", len(data))\n",
        "\n",
        "# -----------------------------\n",
        "# End of Script\n",
        "# -----------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW2O4Mga9rL5",
        "outputId": "a715d455-b884-4615-88c0-6aa0b2617255"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.758\n",
            "Decision Tree Test Accuracy: 0.730\n",
            "Random Forest Test Accuracy: 0.781\n",
            "\n",
            "âœ… Best Model: Random Forest with Accuracy: 0.781\n",
            "Sample prediction -> DID NOT SURVIVE (0)\n",
            "\n",
            "Training features shape: (499, 4)\n",
            "Testing features shape : (215, 4)\n",
            "Total rows used (after dropping missing): 714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ðŸš¢ Analogy: Titanic Ship & Machine Learning Pipeline\n",
        "\n",
        "Imagine you are building a rescue prediction system for passengers on the Titanic.\n",
        "\n",
        "Each step in the pipeline represents a station in the rescue process:"
      ],
      "metadata": {
        "id": "XNVAKND7-nWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step                        | Analogy                                     | ML Equivalent                          |\n",
        "| --------------------------- | ------------------------------------------- | -------------------------------------- |\n",
        "| 1ï¸âƒ£ Passenger check-in      | Collecting data (Age, Sex, Fare, etc.)      | Input data                             |\n",
        "| 2ï¸âƒ£ Weight check            | Scaling data so all features are comparable | `StandardScaler()`                     |                        |\n",
        "| 4ï¸âƒ£ Safety officer decision | Predicting survival using ML model          | Classifier (e.g., Logistic Regression) |\n"
      ],
      "metadata": {
        "id": "iWzBUUim-pt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pipeline connects all stations â€” so each passenger (data row) passes through them automatically and consistently."
      ],
      "metadata": {
        "id": "f0DvnFjT-sYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ§  Step-by-Step Guide\n",
        "\n",
        "ðŸ“˜ Step 1 â€” Import Libraries"
      ],
      "metadata": {
        "id": "6CejtiKw-utt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data handling and ML libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Machine Learning models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "ECaXKisJ-iXF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“— Step 2 â€” Load Titanic Dataset"
      ],
      "metadata": {
        "id": "z524WfBW-y6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Titanic dataset from seaborn\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "# Display first few rows\n",
        "print(titanic.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0raVww6-yTW",
        "outputId": "a7f3b74b-e82f-4b9b-8568-1423b8efe10d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“™ Step 3 â€” Prepare the Data"
      ],
      "metadata": {
        "id": "0zOivDdv-4h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select useful columns\n",
        "data = titanic[['survived', 'pclass', 'sex', 'age', 'fare']]\n",
        "\n",
        "# Remove missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Convert 'sex' column to numeric: male = 0, female = 1\n",
        "data['sex'] = data['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Split into features (X) and target (y)\n",
        "X = data[['pclass', 'sex', 'age', 'fare']]\n",
        "y = data['survived']\n"
      ],
      "metadata": {
        "id": "pgwx1n_T-2cq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“’ Step 4 â€” Split into Training & Test Sets"
      ],
      "metadata": {
        "id": "5j76G_VR-65C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split: 70% train, 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "OHCznQEI-6Rr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“” Step 5 â€” Create Pipelines\n",
        "\n",
        "Each pipeline will:\n",
        "\n",
        "Scale the data using StandardScaler\n",
        "\n",
        "Train a classification model"
      ],
      "metadata": {
        "id": "Mfg-QCaT--p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression pipeline\n",
        "pipe_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Decision Tree pipeline\n",
        "pipe_dt = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Random Forest pipeline\n",
        "pipe_rf = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "hDGjRmQ9-9qp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“• Step 6 â€” Train and Compare Models"
      ],
      "metadata": {
        "id": "8IuKiF1K_EN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store all pipelines in a list\n",
        "pipelines = [pipe_lr, pipe_dt, pipe_rf]\n",
        "model_names = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest'}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "# Loop through each pipeline\n",
        "for i, model in enumerate(pipelines):\n",
        "    model.fit(X_train, y_train)  # Train\n",
        "    score = model.score(X_test, y_test)  # Evaluate\n",
        "    print(f\"{model_names[i]} Test Accuracy: {score:.3f}\")\n",
        "\n",
        "    # Keep track of best model\n",
        "    if score > best_accuracy:\n",
        "        best_accuracy = score\n",
        "        best_model = model_names[i]\n",
        "\n",
        "print(\"\\nâœ… Best Model:\", best_model, \"with Accuracy:\", round(best_accuracy,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eOfKgzk_CPl",
        "outputId": "3a37eb18-af35-4e01-a5df-2968e977f788"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.758\n",
            "Decision Tree Test Accuracy: 0.730\n",
            "Random Forest Test Accuracy: 0.781\n",
            "\n",
            "âœ… Best Model: Random Forest with Accuracy: 0.781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Store all pipelines in a list\n",
        "pipelines = [pipe_lr, pipe_dt, pipe_rf]\n",
        "model_names = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Random Forest'}\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "# Loop through each pipeline\n",
        "for i, model in enumerate(pipelines):\n",
        "    model.fit(X_train, y_train)  # Train\n",
        "    score = model.score(X_test, y_test)  # Evaluate\n",
        "    print(f\"{model_names[i]} Test Accuracy: {score:.3f}\")\n",
        "\n",
        "    # Keep track of best model\n",
        "    if score > best_accuracy:\n",
        "        best_accuracy = score\n",
        "        best_model = model_names[i]\n",
        "\n",
        "print(\"\\nâœ… Best Model:\", best_model, \"with Accuracy:\", round(best_accur"
      ],
      "metadata": {
        "id": "OCpgLCc1_NxI"
      }
    }
  ]
}